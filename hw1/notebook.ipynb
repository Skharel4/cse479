{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model arch 1,batch_8,0.01,regularizer]\n",
      "Epoch 1/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 3.0484 - accuracy: 0.5879 - val_loss: 2.8157 - val_accuracy: 0.6453\n",
      "Epoch 2/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.8581 - accuracy: 0.6125 - val_loss: 2.7308 - val_accuracy: 0.6494\n",
      "Epoch 3/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 2.8593 - accuracy: 0.6169 - val_loss: 2.8643 - val_accuracy: 0.6262\n",
      "Epoch 4/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 2.8406 - accuracy: 0.6187 - val_loss: 2.7590 - val_accuracy: 0.6307\n",
      "Epoch 5/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 2.8438 - accuracy: 0.6170 - val_loss: 3.0142 - val_accuracy: 0.6269\n",
      "Epoch 6/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 2.8512 - accuracy: 0.6197 - val_loss: 2.7975 - val_accuracy: 0.5975\n",
      "Model arch 1,[batch_8,0.01,regularizer]=>Accuracy:0.649,F1:0.626\n",
      "Working on model arch 1,batch_8,0.01,no_regularizer]\n",
      "Epoch 1/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 0.6789 - accuracy: 0.7504 - val_loss: 0.5315 - val_accuracy: 0.8033\n",
      "Epoch 2/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 0.5571 - accuracy: 0.8041 - val_loss: 0.6061 - val_accuracy: 0.8138\n",
      "Epoch 3/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 0.5356 - accuracy: 0.8183 - val_loss: 0.5060 - val_accuracy: 0.8313\n",
      "Epoch 4/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 0.5219 - accuracy: 0.8226 - val_loss: 0.4795 - val_accuracy: 0.8397\n",
      "Epoch 5/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 0.5141 - accuracy: 0.8244 - val_loss: 0.4948 - val_accuracy: 0.8416\n",
      "Epoch 6/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 0.5249 - accuracy: 0.8188 - val_loss: 0.6042 - val_accuracy: 0.7861\n",
      "Epoch 7/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 0.5643 - accuracy: 0.7907 - val_loss: 0.5753 - val_accuracy: 0.7859\n",
      "Epoch 8/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 0.5634 - accuracy: 0.7822 - val_loss: 0.5830 - val_accuracy: 0.7963\n",
      "Model arch 1,[batch_8,0.01,no_regularizer]=>Accuracy:0.840,F1:0.838\n",
      "Working on model arch 1,batch_8,0.001,regularizer]\n",
      "Epoch 1/200\n",
      "6000/6000 [==============================] - 8s 1ms/step - loss: 1.8552 - accuracy: 0.6813 - val_loss: 1.2708 - val_accuracy: 0.7312\n",
      "Epoch 2/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 1.2664 - accuracy: 0.7356 - val_loss: 1.1997 - val_accuracy: 0.7511\n",
      "Epoch 3/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 1.2215 - accuracy: 0.7436 - val_loss: 1.1619 - val_accuracy: 0.7585\n",
      "Epoch 4/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 1.1966 - accuracy: 0.7463 - val_loss: 1.1340 - val_accuracy: 0.7627\n",
      "Epoch 5/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 1.1802 - accuracy: 0.7490 - val_loss: 1.1122 - val_accuracy: 0.7692\n",
      "Epoch 6/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.1675 - accuracy: 0.7496 - val_loss: 1.1011 - val_accuracy: 0.7717\n",
      "Epoch 7/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 1.1583 - accuracy: 0.7502 - val_loss: 1.0928 - val_accuracy: 0.7705\n",
      "Epoch 8/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 1.1510 - accuracy: 0.7529 - val_loss: 1.0827 - val_accuracy: 0.7732\n",
      "Epoch 9/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 1.1454 - accuracy: 0.7526 - val_loss: 1.0746 - val_accuracy: 0.7781\n",
      "Epoch 10/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 1.1408 - accuracy: 0.7534 - val_loss: 1.0824 - val_accuracy: 0.7722\n",
      "Epoch 11/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 1.1367 - accuracy: 0.7534 - val_loss: 1.0786 - val_accuracy: 0.7747\n",
      "Epoch 12/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.1337 - accuracy: 0.7533 - val_loss: 1.0843 - val_accuracy: 0.7713\n",
      "Epoch 13/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.1304 - accuracy: 0.7539 - val_loss: 1.0866 - val_accuracy: 0.7707\n",
      "Model arch 1,[batch_8,0.001,regularizer]=>Accuracy:0.778,F1:0.777\n",
      "Working on model arch 1,batch_8,0.001,no_regularizer]\n",
      "Epoch 1/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 0.4997 - accuracy: 0.8187 - val_loss: 0.4071 - val_accuracy: 0.8528\n",
      "Epoch 2/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 0.3812 - accuracy: 0.8599 - val_loss: 0.3830 - val_accuracy: 0.8615\n",
      "Epoch 3/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 0.3441 - accuracy: 0.8734 - val_loss: 0.3720 - val_accuracy: 0.8676\n",
      "Epoch 4/200\n",
      "6000/6000 [==============================] - 6s 991us/step - loss: 0.3223 - accuracy: 0.8821 - val_loss: 0.3678 - val_accuracy: 0.8658\n",
      "Epoch 5/200\n",
      "6000/6000 [==============================] - 6s 959us/step - loss: 0.3031 - accuracy: 0.8875 - val_loss: 0.3505 - val_accuracy: 0.8717\n",
      "Epoch 6/200\n",
      "6000/6000 [==============================] - 6s 999us/step - loss: 0.2883 - accuracy: 0.8928 - val_loss: 0.3498 - val_accuracy: 0.8773\n",
      "Epoch 7/200\n",
      "6000/6000 [==============================] - 6s 1000us/step - loss: 0.2759 - accuracy: 0.8964 - val_loss: 0.3607 - val_accuracy: 0.8780\n",
      "Epoch 8/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 0.2680 - accuracy: 0.9000 - val_loss: 0.3809 - val_accuracy: 0.8761\n",
      "Epoch 9/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 0.2558 - accuracy: 0.9042 - val_loss: 0.3525 - val_accuracy: 0.8844\n",
      "Epoch 10/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 0.2492 - accuracy: 0.9072 - val_loss: 0.3715 - val_accuracy: 0.8776\n",
      "Model arch 1,[batch_8,0.001,no_regularizer]=>Accuracy:0.877,F1:0.875\n",
      "Working on model arch 1,batch_32,0.01,regularizer]\n",
      "Epoch 1/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 2.9744 - accuracy: 0.6339 - val_loss: 2.5027 - val_accuracy: 0.6853\n",
      "Epoch 2/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 2.5698 - accuracy: 0.6594 - val_loss: 2.4645 - val_accuracy: 0.6878\n",
      "Epoch 3/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 2.5503 - accuracy: 0.6647 - val_loss: 2.6421 - val_accuracy: 0.6148\n",
      "Epoch 4/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 2.5582 - accuracy: 0.6640 - val_loss: 2.4351 - val_accuracy: 0.6889\n",
      "Epoch 5/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 2.5367 - accuracy: 0.6627 - val_loss: 2.5717 - val_accuracy: 0.6813\n",
      "Epoch 6/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 2.5354 - accuracy: 0.6672 - val_loss: 2.5732 - val_accuracy: 0.6382\n",
      "Epoch 7/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 2.5353 - accuracy: 0.6656 - val_loss: 2.4652 - val_accuracy: 0.6805\n",
      "Epoch 8/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 2.5316 - accuracy: 0.6681 - val_loss: 2.6028 - val_accuracy: 0.6351\n",
      "Model arch 1,[batch_32,0.01,regularizer]=>Accuracy:0.689,F1:0.667\n",
      "Working on model arch 1,batch_32,0.01,no_regularizer]\n",
      "Epoch 1/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5691 - accuracy: 0.7952 - val_loss: 0.4459 - val_accuracy: 0.8392\n",
      "Epoch 2/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4584 - accuracy: 0.8363 - val_loss: 0.4492 - val_accuracy: 0.8346\n",
      "Epoch 3/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4362 - accuracy: 0.8441 - val_loss: 0.4440 - val_accuracy: 0.8300\n",
      "Epoch 4/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4188 - accuracy: 0.8504 - val_loss: 0.4356 - val_accuracy: 0.8453\n",
      "Epoch 5/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4069 - accuracy: 0.8530 - val_loss: 0.4139 - val_accuracy: 0.8498\n",
      "Epoch 6/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3997 - accuracy: 0.8562 - val_loss: 0.4113 - val_accuracy: 0.8581\n",
      "Epoch 7/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4011 - accuracy: 0.8577 - val_loss: 0.3993 - val_accuracy: 0.8602\n",
      "Epoch 8/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3964 - accuracy: 0.8583 - val_loss: 0.4282 - val_accuracy: 0.8571\n",
      "Epoch 9/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3824 - accuracy: 0.8627 - val_loss: 0.4499 - val_accuracy: 0.8529\n",
      "Epoch 10/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3803 - accuracy: 0.8624 - val_loss: 0.4257 - val_accuracy: 0.8559\n",
      "Epoch 11/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3738 - accuracy: 0.8658 - val_loss: 0.4131 - val_accuracy: 0.8570\n",
      "Model arch 1,[batch_32,0.01,no_regularizer]=>Accuracy:0.860,F1:0.857\n",
      "Working on model arch 1,batch_32,0.001,regularizer]\n",
      "Epoch 1/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 2.9591 - accuracy: 0.6764 - val_loss: 1.3796 - val_accuracy: 0.7008\n",
      "Epoch 2/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.2902 - accuracy: 0.7308 - val_loss: 1.2906 - val_accuracy: 0.7132\n",
      "Epoch 3/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.2230 - accuracy: 0.7453 - val_loss: 1.2623 - val_accuracy: 0.7137\n",
      "Epoch 4/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1825 - accuracy: 0.7529 - val_loss: 1.2284 - val_accuracy: 0.7231\n",
      "Epoch 5/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1536 - accuracy: 0.7590 - val_loss: 1.2012 - val_accuracy: 0.7295\n",
      "Epoch 6/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1323 - accuracy: 0.7619 - val_loss: 1.1819 - val_accuracy: 0.7358\n",
      "Epoch 7/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1164 - accuracy: 0.7651 - val_loss: 1.1666 - val_accuracy: 0.7372\n",
      "Epoch 8/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1035 - accuracy: 0.7672 - val_loss: 1.1545 - val_accuracy: 0.7385\n",
      "Epoch 9/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0933 - accuracy: 0.7685 - val_loss: 1.1488 - val_accuracy: 0.7401\n",
      "Epoch 10/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0838 - accuracy: 0.7692 - val_loss: 1.1400 - val_accuracy: 0.7412\n",
      "Epoch 11/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0758 - accuracy: 0.7707 - val_loss: 1.1318 - val_accuracy: 0.7411\n",
      "Epoch 12/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0682 - accuracy: 0.7717 - val_loss: 1.1226 - val_accuracy: 0.7426\n",
      "Epoch 13/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0619 - accuracy: 0.7721 - val_loss: 1.1187 - val_accuracy: 0.7427\n",
      "Epoch 14/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0558 - accuracy: 0.7726 - val_loss: 1.1100 - val_accuracy: 0.7438\n",
      "Epoch 15/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0501 - accuracy: 0.7732 - val_loss: 1.1022 - val_accuracy: 0.7461\n",
      "Epoch 16/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0451 - accuracy: 0.7736 - val_loss: 1.0957 - val_accuracy: 0.7477\n",
      "Epoch 17/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0409 - accuracy: 0.7742 - val_loss: 1.0936 - val_accuracy: 0.7459\n",
      "Epoch 18/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0364 - accuracy: 0.7746 - val_loss: 1.0860 - val_accuracy: 0.7471\n",
      "Epoch 19/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0327 - accuracy: 0.7749 - val_loss: 1.0828 - val_accuracy: 0.7467\n",
      "Epoch 20/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0288 - accuracy: 0.7753 - val_loss: 1.0801 - val_accuracy: 0.7459\n",
      "Epoch 21/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0257 - accuracy: 0.7754 - val_loss: 1.0796 - val_accuracy: 0.7457\n",
      "Epoch 22/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0230 - accuracy: 0.7759 - val_loss: 1.0703 - val_accuracy: 0.7488\n",
      "Epoch 23/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0202 - accuracy: 0.7761 - val_loss: 1.0723 - val_accuracy: 0.7460\n",
      "Epoch 24/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0177 - accuracy: 0.7766 - val_loss: 1.0696 - val_accuracy: 0.7459\n",
      "Epoch 25/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0152 - accuracy: 0.7771 - val_loss: 1.0666 - val_accuracy: 0.7457\n",
      "Epoch 26/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0132 - accuracy: 0.7770 - val_loss: 1.0623 - val_accuracy: 0.7470\n",
      "Epoch 27/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0109 - accuracy: 0.7777 - val_loss: 1.0589 - val_accuracy: 0.7477\n",
      "Epoch 28/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0091 - accuracy: 0.7774 - val_loss: 1.0566 - val_accuracy: 0.7471\n",
      "Epoch 29/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0074 - accuracy: 0.7775 - val_loss: 1.0556 - val_accuracy: 0.7472\n",
      "Epoch 30/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0059 - accuracy: 0.7773 - val_loss: 1.0539 - val_accuracy: 0.7474\n",
      "Epoch 31/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0042 - accuracy: 0.7780 - val_loss: 1.0524 - val_accuracy: 0.7482\n",
      "Epoch 32/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0026 - accuracy: 0.7779 - val_loss: 1.0491 - val_accuracy: 0.7485\n",
      "Epoch 33/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.0011 - accuracy: 0.7780 - val_loss: 1.0450 - val_accuracy: 0.7510\n",
      "Epoch 34/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9994 - accuracy: 0.7783 - val_loss: 1.0425 - val_accuracy: 0.7513\n",
      "Epoch 35/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9983 - accuracy: 0.7784 - val_loss: 1.0398 - val_accuracy: 0.7514\n",
      "Epoch 36/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9966 - accuracy: 0.7788 - val_loss: 1.0383 - val_accuracy: 0.7537\n",
      "Epoch 37/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9954 - accuracy: 0.7787 - val_loss: 1.0320 - val_accuracy: 0.7553\n",
      "Epoch 38/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9944 - accuracy: 0.7786 - val_loss: 1.0309 - val_accuracy: 0.7558\n",
      "Epoch 39/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9932 - accuracy: 0.7786 - val_loss: 1.0281 - val_accuracy: 0.7568\n",
      "Epoch 40/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9920 - accuracy: 0.7786 - val_loss: 1.0253 - val_accuracy: 0.7571\n",
      "Epoch 41/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9912 - accuracy: 0.7789 - val_loss: 1.0228 - val_accuracy: 0.7574\n",
      "Epoch 42/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9901 - accuracy: 0.7788 - val_loss: 1.0216 - val_accuracy: 0.7579\n",
      "Epoch 43/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9893 - accuracy: 0.7794 - val_loss: 1.0201 - val_accuracy: 0.7581\n",
      "Epoch 44/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9884 - accuracy: 0.7790 - val_loss: 1.0211 - val_accuracy: 0.7569\n",
      "Epoch 45/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9874 - accuracy: 0.7789 - val_loss: 1.0170 - val_accuracy: 0.7595\n",
      "Epoch 46/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9866 - accuracy: 0.7787 - val_loss: 1.0179 - val_accuracy: 0.7573\n",
      "Epoch 47/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9857 - accuracy: 0.7788 - val_loss: 1.0195 - val_accuracy: 0.7562\n",
      "Epoch 48/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9847 - accuracy: 0.7786 - val_loss: 1.0162 - val_accuracy: 0.7581\n",
      "Epoch 49/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9842 - accuracy: 0.7788 - val_loss: 1.0158 - val_accuracy: 0.7577\n",
      "Epoch 50/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9834 - accuracy: 0.7787 - val_loss: 1.0129 - val_accuracy: 0.7589\n",
      "Epoch 51/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9824 - accuracy: 0.7788 - val_loss: 1.0063 - val_accuracy: 0.7627\n",
      "Epoch 52/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9817 - accuracy: 0.7789 - val_loss: 1.0076 - val_accuracy: 0.7616\n",
      "Epoch 53/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9810 - accuracy: 0.7792 - val_loss: 1.0097 - val_accuracy: 0.7592\n",
      "Epoch 54/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9801 - accuracy: 0.7790 - val_loss: 1.0031 - val_accuracy: 0.7633\n",
      "Epoch 55/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9795 - accuracy: 0.7790 - val_loss: 1.0017 - val_accuracy: 0.7647\n",
      "Epoch 56/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9787 - accuracy: 0.7789 - val_loss: 1.0001 - val_accuracy: 0.7653\n",
      "Epoch 57/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9779 - accuracy: 0.7790 - val_loss: 0.9986 - val_accuracy: 0.7661\n",
      "Epoch 58/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9773 - accuracy: 0.7788 - val_loss: 0.9969 - val_accuracy: 0.7661\n",
      "Epoch 59/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9765 - accuracy: 0.7792 - val_loss: 0.9974 - val_accuracy: 0.7661\n",
      "Epoch 60/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9758 - accuracy: 0.7797 - val_loss: 0.9959 - val_accuracy: 0.7657\n",
      "Epoch 61/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9755 - accuracy: 0.7795 - val_loss: 0.9953 - val_accuracy: 0.7656\n",
      "Epoch 62/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9750 - accuracy: 0.7799 - val_loss: 0.9948 - val_accuracy: 0.7657\n",
      "Epoch 63/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9745 - accuracy: 0.7794 - val_loss: 0.9924 - val_accuracy: 0.7669\n",
      "Epoch 64/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9742 - accuracy: 0.7795 - val_loss: 0.9931 - val_accuracy: 0.7663\n",
      "Epoch 65/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9737 - accuracy: 0.7796 - val_loss: 0.9911 - val_accuracy: 0.7669\n",
      "Epoch 66/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9733 - accuracy: 0.7797 - val_loss: 0.9910 - val_accuracy: 0.7676\n",
      "Epoch 67/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9727 - accuracy: 0.7796 - val_loss: 0.9911 - val_accuracy: 0.7671\n",
      "Epoch 68/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9724 - accuracy: 0.7795 - val_loss: 0.9902 - val_accuracy: 0.7669\n",
      "Epoch 69/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9718 - accuracy: 0.7799 - val_loss: 0.9899 - val_accuracy: 0.7671\n",
      "Epoch 70/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9711 - accuracy: 0.7802 - val_loss: 0.9893 - val_accuracy: 0.7669\n",
      "Epoch 71/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9707 - accuracy: 0.7801 - val_loss: 0.9898 - val_accuracy: 0.7668\n",
      "Epoch 72/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9705 - accuracy: 0.7801 - val_loss: 0.9889 - val_accuracy: 0.7674\n",
      "Epoch 73/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9701 - accuracy: 0.7800 - val_loss: 0.9878 - val_accuracy: 0.7664\n",
      "Epoch 74/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9697 - accuracy: 0.7803 - val_loss: 0.9894 - val_accuracy: 0.7661\n",
      "Epoch 75/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9692 - accuracy: 0.7800 - val_loss: 0.9869 - val_accuracy: 0.7675\n",
      "Epoch 76/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9687 - accuracy: 0.7806 - val_loss: 0.9852 - val_accuracy: 0.7681\n",
      "Epoch 77/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9683 - accuracy: 0.7807 - val_loss: 0.9840 - val_accuracy: 0.7678\n",
      "Epoch 78/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9680 - accuracy: 0.7801 - val_loss: 0.9839 - val_accuracy: 0.7684\n",
      "Epoch 79/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9675 - accuracy: 0.7804 - val_loss: 0.9845 - val_accuracy: 0.7679\n",
      "Epoch 80/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9670 - accuracy: 0.7809 - val_loss: 0.9850 - val_accuracy: 0.7669\n",
      "Epoch 81/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9664 - accuracy: 0.7810 - val_loss: 0.9849 - val_accuracy: 0.7673\n",
      "Epoch 82/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9664 - accuracy: 0.7811 - val_loss: 0.9808 - val_accuracy: 0.7691\n",
      "Epoch 83/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9657 - accuracy: 0.7812 - val_loss: 0.9834 - val_accuracy: 0.7673\n",
      "Epoch 84/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9650 - accuracy: 0.7811 - val_loss: 0.9822 - val_accuracy: 0.7676\n",
      "Epoch 85/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9652 - accuracy: 0.7811 - val_loss: 0.9815 - val_accuracy: 0.7680\n",
      "Epoch 86/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.9648 - accuracy: 0.7811 - val_loss: 0.9827 - val_accuracy: 0.7673\n",
      "Model arch 1,[batch_32,0.001,regularizer]=>Accuracy:0.769,F1:0.759\n",
      "Working on model arch 1,batch_32,0.001,no_regularizer]\n",
      "Epoch 1/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5091 - accuracy: 0.8177 - val_loss: 0.3887 - val_accuracy: 0.8602\n",
      "Epoch 2/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3778 - accuracy: 0.8616 - val_loss: 0.3902 - val_accuracy: 0.8600\n",
      "Epoch 3/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3400 - accuracy: 0.8746 - val_loss: 0.3856 - val_accuracy: 0.8622\n",
      "Epoch 4/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3143 - accuracy: 0.8821 - val_loss: 0.3670 - val_accuracy: 0.8712\n",
      "Epoch 5/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2967 - accuracy: 0.8901 - val_loss: 0.3489 - val_accuracy: 0.8752\n",
      "Epoch 6/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2790 - accuracy: 0.8957 - val_loss: 0.3293 - val_accuracy: 0.8839\n",
      "Epoch 7/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2646 - accuracy: 0.9010 - val_loss: 0.3317 - val_accuracy: 0.8841\n",
      "Epoch 8/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2531 - accuracy: 0.9050 - val_loss: 0.3312 - val_accuracy: 0.8849\n",
      "Epoch 9/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2401 - accuracy: 0.9097 - val_loss: 0.3800 - val_accuracy: 0.8742\n",
      "Epoch 10/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2316 - accuracy: 0.9119 - val_loss: 0.3328 - val_accuracy: 0.8893\n",
      "Model arch 1,[batch_32,0.001,no_regularizer]=>Accuracy:0.884,F1:0.882\n",
      "Working on model arch 2,batch_8,0.01,regularizer]\n",
      "Epoch 1/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 4.2173 - accuracy: 0.6192 - val_loss: 3.8474 - val_accuracy: 0.6680\n",
      "Epoch 2/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 3.9663 - accuracy: 0.6381 - val_loss: 3.8402 - val_accuracy: 0.6917\n",
      "Epoch 3/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 3.9645 - accuracy: 0.6446 - val_loss: 3.8664 - val_accuracy: 0.6733\n",
      "Epoch 4/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 3.9574 - accuracy: 0.6402 - val_loss: 3.8565 - val_accuracy: 0.6549\n",
      "Epoch 5/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 3.9617 - accuracy: 0.6419 - val_loss: 3.8514 - val_accuracy: 0.6725\n",
      "Epoch 6/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 3.9435 - accuracy: 0.6378 - val_loss: 3.9908 - val_accuracy: 0.6103\n",
      "Model arch 2,[batch_8,0.01,regularizer]=>Accuracy:0.692,F1:0.672\n",
      "Working on model arch 2,batch_8,0.01,no_regularizer]\n",
      "Epoch 1/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 0.6199 - accuracy: 0.7853 - val_loss: 0.5513 - val_accuracy: 0.8169\n",
      "Epoch 2/200\n",
      "6000/6000 [==============================] - 6s 930us/step - loss: 0.5362 - accuracy: 0.8191 - val_loss: 0.5405 - val_accuracy: 0.8287\n",
      "Epoch 3/200\n",
      "6000/6000 [==============================] - 6s 935us/step - loss: 0.5138 - accuracy: 0.8284 - val_loss: 0.5522 - val_accuracy: 0.8225\n",
      "Epoch 4/200\n",
      "6000/6000 [==============================] - 6s 929us/step - loss: 0.5019 - accuracy: 0.8324 - val_loss: 0.5110 - val_accuracy: 0.8370\n",
      "Epoch 5/200\n",
      "6000/6000 [==============================] - 6s 919us/step - loss: 0.4883 - accuracy: 0.8345 - val_loss: 0.5369 - val_accuracy: 0.8272\n",
      "Epoch 6/200\n",
      "6000/6000 [==============================] - 6s 937us/step - loss: 0.4881 - accuracy: 0.8353 - val_loss: 0.6513 - val_accuracy: 0.8158\n",
      "Epoch 7/200\n",
      "6000/6000 [==============================] - 6s 936us/step - loss: 0.4861 - accuracy: 0.8370 - val_loss: 0.5487 - val_accuracy: 0.8407\n",
      "Epoch 8/200\n",
      "6000/6000 [==============================] - 6s 965us/step - loss: 0.4785 - accuracy: 0.8384 - val_loss: 0.5826 - val_accuracy: 0.8307\n",
      "Model arch 2,[batch_8,0.01,no_regularizer]=>Accuracy:0.837,F1:0.834\n",
      "Working on model arch 2,batch_8,0.001,regularizer]\n",
      "Epoch 1/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 2.1107 - accuracy: 0.6932 - val_loss: 1.4310 - val_accuracy: 0.7413\n",
      "Epoch 2/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.4091 - accuracy: 0.7424 - val_loss: 1.3515 - val_accuracy: 0.7565\n",
      "Epoch 3/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.3620 - accuracy: 0.7512 - val_loss: 1.3098 - val_accuracy: 0.7640\n",
      "Epoch 4/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.3295 - accuracy: 0.7554 - val_loss: 1.3056 - val_accuracy: 0.7595\n",
      "Epoch 5/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.3117 - accuracy: 0.7581 - val_loss: 1.2799 - val_accuracy: 0.7625\n",
      "Epoch 6/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2992 - accuracy: 0.7600 - val_loss: 1.2623 - val_accuracy: 0.7645\n",
      "Epoch 7/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2862 - accuracy: 0.7604 - val_loss: 1.2589 - val_accuracy: 0.7655\n",
      "Epoch 8/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2828 - accuracy: 0.7620 - val_loss: 1.2507 - val_accuracy: 0.7669\n",
      "Epoch 9/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2822 - accuracy: 0.7623 - val_loss: 1.2504 - val_accuracy: 0.7669\n",
      "Epoch 10/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2787 - accuracy: 0.7630 - val_loss: 1.2470 - val_accuracy: 0.7667\n",
      "Epoch 11/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2768 - accuracy: 0.7632 - val_loss: 1.2358 - val_accuracy: 0.7657\n",
      "Epoch 12/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2766 - accuracy: 0.7632 - val_loss: 1.2335 - val_accuracy: 0.7671\n",
      "Epoch 13/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2729 - accuracy: 0.7633 - val_loss: 1.2262 - val_accuracy: 0.7667\n",
      "Epoch 14/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2604 - accuracy: 0.7627 - val_loss: 1.2196 - val_accuracy: 0.7671\n",
      "Epoch 15/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2463 - accuracy: 0.7640 - val_loss: 1.2056 - val_accuracy: 0.7706\n",
      "Epoch 16/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2474 - accuracy: 0.7639 - val_loss: 1.1982 - val_accuracy: 0.7722\n",
      "Epoch 17/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2430 - accuracy: 0.7641 - val_loss: 1.1920 - val_accuracy: 0.7730\n",
      "Epoch 18/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2388 - accuracy: 0.7630 - val_loss: 1.1919 - val_accuracy: 0.7748\n",
      "Epoch 19/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2332 - accuracy: 0.7630 - val_loss: 1.1744 - val_accuracy: 0.7733\n",
      "Epoch 20/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2188 - accuracy: 0.7640 - val_loss: 1.1733 - val_accuracy: 0.7734\n",
      "Epoch 21/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2162 - accuracy: 0.7641 - val_loss: 1.1690 - val_accuracy: 0.7765\n",
      "Epoch 22/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2140 - accuracy: 0.7625 - val_loss: 1.1601 - val_accuracy: 0.7783\n",
      "Epoch 23/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2131 - accuracy: 0.7638 - val_loss: 1.1567 - val_accuracy: 0.7775\n",
      "Epoch 24/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2129 - accuracy: 0.7635 - val_loss: 1.1620 - val_accuracy: 0.7753\n",
      "Epoch 25/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 1.2113 - accuracy: 0.7638 - val_loss: 1.1549 - val_accuracy: 0.7774\n",
      "Epoch 26/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 1.2086 - accuracy: 0.7644 - val_loss: 1.1518 - val_accuracy: 0.7788\n",
      "Epoch 27/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2082 - accuracy: 0.7638 - val_loss: 1.1545 - val_accuracy: 0.7780\n",
      "Epoch 28/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2068 - accuracy: 0.7639 - val_loss: 1.1508 - val_accuracy: 0.7768\n",
      "Epoch 29/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2055 - accuracy: 0.7636 - val_loss: 1.1488 - val_accuracy: 0.7784\n",
      "Epoch 30/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 1.2056 - accuracy: 0.7642 - val_loss: 1.1491 - val_accuracy: 0.7807\n",
      "Epoch 31/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 1.2040 - accuracy: 0.7642 - val_loss: 1.1456 - val_accuracy: 0.7822\n",
      "Epoch 32/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2020 - accuracy: 0.7644 - val_loss: 1.1477 - val_accuracy: 0.7812\n",
      "Epoch 33/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2025 - accuracy: 0.7642 - val_loss: 1.1432 - val_accuracy: 0.7826\n",
      "Epoch 34/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2016 - accuracy: 0.7645 - val_loss: 1.1424 - val_accuracy: 0.7816\n",
      "Epoch 35/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.2016 - accuracy: 0.7648 - val_loss: 1.1454 - val_accuracy: 0.7805\n",
      "Epoch 36/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.1996 - accuracy: 0.7646 - val_loss: 1.1314 - val_accuracy: 0.7776\n",
      "Epoch 37/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.1991 - accuracy: 0.7648 - val_loss: 1.1341 - val_accuracy: 0.7773\n",
      "Epoch 38/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.1976 - accuracy: 0.7637 - val_loss: 1.1256 - val_accuracy: 0.7809\n",
      "Epoch 39/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.1977 - accuracy: 0.7631 - val_loss: 1.1330 - val_accuracy: 0.7762\n",
      "Epoch 40/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.1974 - accuracy: 0.7636 - val_loss: 1.1329 - val_accuracy: 0.7806\n",
      "Epoch 41/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.1964 - accuracy: 0.7641 - val_loss: 1.1299 - val_accuracy: 0.7798\n",
      "Epoch 42/200\n",
      "6000/6000 [==============================] - 6s 1ms/step - loss: 1.1973 - accuracy: 0.7633 - val_loss: 1.1284 - val_accuracy: 0.7800\n",
      "Model arch 2,[batch_8,0.001,regularizer]=>Accuracy:0.781,F1:0.776\n",
      "Working on model arch 2,batch_8,0.001,no_regularizer]\n",
      "Epoch 1/200\n",
      "6000/6000 [==============================] - 7s 1ms/step - loss: 0.4944 - accuracy: 0.8203 - val_loss: 0.4111 - val_accuracy: 0.8504\n",
      "Epoch 2/200\n",
      "6000/6000 [==============================] - 6s 995us/step - loss: 0.3733 - accuracy: 0.8622 - val_loss: 0.4018 - val_accuracy: 0.8523\n",
      "Epoch 3/200\n",
      "6000/6000 [==============================] - 6s 963us/step - loss: 0.3338 - accuracy: 0.8755 - val_loss: 0.3937 - val_accuracy: 0.8602\n",
      "Epoch 4/200\n",
      "6000/6000 [==============================] - 6s 961us/step - loss: 0.3098 - accuracy: 0.8841 - val_loss: 0.3704 - val_accuracy: 0.8668\n",
      "Epoch 5/200\n",
      "6000/6000 [==============================] - 6s 956us/step - loss: 0.2923 - accuracy: 0.8906 - val_loss: 0.3490 - val_accuracy: 0.8765\n",
      "Epoch 6/200\n",
      "6000/6000 [==============================] - 6s 979us/step - loss: 0.2758 - accuracy: 0.8970 - val_loss: 0.3702 - val_accuracy: 0.8722\n",
      "Epoch 7/200\n",
      "6000/6000 [==============================] - 6s 954us/step - loss: 0.2611 - accuracy: 0.9022 - val_loss: 0.3569 - val_accuracy: 0.8799\n",
      "Epoch 8/200\n",
      "6000/6000 [==============================] - 6s 991us/step - loss: 0.2497 - accuracy: 0.9066 - val_loss: 0.3717 - val_accuracy: 0.8766\n",
      "Epoch 9/200\n",
      "6000/6000 [==============================] - 6s 980us/step - loss: 0.2413 - accuracy: 0.9099 - val_loss: 0.3992 - val_accuracy: 0.8774\n",
      "Model arch 2,[batch_8,0.001,no_regularizer]=>Accuracy:0.876,F1:0.874\n",
      "Working on model arch 2,batch_32,0.01,regularizer]\n",
      "Epoch 1/200\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 4.1755 - accuracy: 0.6766 - val_loss: 3.5460 - val_accuracy: 0.7253\n",
      "Epoch 2/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 3.5699 - accuracy: 0.7034 - val_loss: 3.4500 - val_accuracy: 0.7359\n",
      "Epoch 3/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 3.5507 - accuracy: 0.7044 - val_loss: 3.4789 - val_accuracy: 0.7355\n",
      "Epoch 4/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 3.5350 - accuracy: 0.7052 - val_loss: 3.4708 - val_accuracy: 0.7259\n",
      "Epoch 5/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 3.5424 - accuracy: 0.7041 - val_loss: 3.3815 - val_accuracy: 0.7512\n",
      "Epoch 6/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 3.5205 - accuracy: 0.7056 - val_loss: 3.3695 - val_accuracy: 0.7511\n",
      "Epoch 7/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 3.5201 - accuracy: 0.7060 - val_loss: 3.6390 - val_accuracy: 0.6680\n",
      "Epoch 8/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 3.5489 - accuracy: 0.7006 - val_loss: 3.4159 - val_accuracy: 0.7204\n",
      "Epoch 9/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 3.5162 - accuracy: 0.7076 - val_loss: 3.4125 - val_accuracy: 0.7382\n",
      "Epoch 10/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 3.5399 - accuracy: 0.7051 - val_loss: 3.4263 - val_accuracy: 0.7425\n",
      "Model arch 2,[batch_32,0.01,regularizer]=>Accuracy:0.751,F1:0.745\n",
      "Working on model arch 2,batch_32,0.01,no_regularizer]\n",
      "Epoch 1/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5510 - accuracy: 0.8055 - val_loss: 0.4516 - val_accuracy: 0.8368\n",
      "Epoch 2/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4461 - accuracy: 0.8390 - val_loss: 0.4490 - val_accuracy: 0.8398\n",
      "Epoch 3/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4215 - accuracy: 0.8483 - val_loss: 0.4667 - val_accuracy: 0.8309\n",
      "Epoch 4/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4079 - accuracy: 0.8511 - val_loss: 0.5124 - val_accuracy: 0.8198\n",
      "Epoch 5/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3936 - accuracy: 0.8563 - val_loss: 0.4546 - val_accuracy: 0.8394\n",
      "Epoch 6/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3892 - accuracy: 0.8585 - val_loss: 0.4591 - val_accuracy: 0.8402\n",
      "Model arch 2,[batch_32,0.01,no_regularizer]=>Accuracy:0.840,F1:0.837\n",
      "Working on model arch 2,batch_32,0.001,regularizer]\n",
      "Epoch 1/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 3.2262 - accuracy: 0.6845 - val_loss: 1.4666 - val_accuracy: 0.7141\n",
      "Epoch 2/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.3954 - accuracy: 0.7392 - val_loss: 1.3658 - val_accuracy: 0.7304\n",
      "Epoch 3/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.3118 - accuracy: 0.7568 - val_loss: 1.3228 - val_accuracy: 0.7407\n",
      "Epoch 4/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.2635 - accuracy: 0.7646 - val_loss: 1.2744 - val_accuracy: 0.7553\n",
      "Epoch 5/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.2328 - accuracy: 0.7710 - val_loss: 1.2467 - val_accuracy: 0.7586\n",
      "Epoch 6/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.2135 - accuracy: 0.7752 - val_loss: 1.2363 - val_accuracy: 0.7597\n",
      "Epoch 7/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1990 - accuracy: 0.7772 - val_loss: 1.2143 - val_accuracy: 0.7663\n",
      "Epoch 8/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1879 - accuracy: 0.7790 - val_loss: 1.1992 - val_accuracy: 0.7732\n",
      "Epoch 9/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1786 - accuracy: 0.7816 - val_loss: 1.1875 - val_accuracy: 0.7705\n",
      "Epoch 10/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1703 - accuracy: 0.7835 - val_loss: 1.1689 - val_accuracy: 0.7857\n",
      "Epoch 11/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1636 - accuracy: 0.7849 - val_loss: 1.1672 - val_accuracy: 0.7744\n",
      "Epoch 12/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1589 - accuracy: 0.7853 - val_loss: 1.1630 - val_accuracy: 0.7815\n",
      "Epoch 13/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1533 - accuracy: 0.7867 - val_loss: 1.1587 - val_accuracy: 0.7817\n",
      "Epoch 14/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1513 - accuracy: 0.7872 - val_loss: 1.1632 - val_accuracy: 0.7823\n",
      "Epoch 15/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1474 - accuracy: 0.7879 - val_loss: 1.1443 - val_accuracy: 0.7840\n",
      "Epoch 16/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1439 - accuracy: 0.7880 - val_loss: 1.1325 - val_accuracy: 0.7871\n",
      "Epoch 17/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1396 - accuracy: 0.7890 - val_loss: 1.1405 - val_accuracy: 0.7842\n",
      "Epoch 18/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1298 - accuracy: 0.7895 - val_loss: 1.1291 - val_accuracy: 0.7833\n",
      "Epoch 19/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1259 - accuracy: 0.7906 - val_loss: 1.1209 - val_accuracy: 0.7811\n",
      "Epoch 20/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1235 - accuracy: 0.7899 - val_loss: 1.1323 - val_accuracy: 0.7832\n",
      "Epoch 21/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1224 - accuracy: 0.7906 - val_loss: 1.1248 - val_accuracy: 0.7868\n",
      "Epoch 22/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1207 - accuracy: 0.7903 - val_loss: 1.1143 - val_accuracy: 0.7867\n",
      "Epoch 23/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1184 - accuracy: 0.7904 - val_loss: 1.1095 - val_accuracy: 0.7878\n",
      "Epoch 24/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1170 - accuracy: 0.7906 - val_loss: 1.1347 - val_accuracy: 0.7818\n",
      "Epoch 25/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1153 - accuracy: 0.7905 - val_loss: 1.1139 - val_accuracy: 0.7893\n",
      "Epoch 26/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1118 - accuracy: 0.7922 - val_loss: 1.1103 - val_accuracy: 0.7872\n",
      "Epoch 27/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 1.1126 - accuracy: 0.7917 - val_loss: 1.1146 - val_accuracy: 0.7875\n",
      "Model arch 2,[batch_32,0.001,regularizer]=>Accuracy:0.788,F1:0.779\n",
      "Working on model arch 2,batch_32,0.001,no_regularizer]\n",
      "Epoch 1/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5024 - accuracy: 0.8214 - val_loss: 0.3970 - val_accuracy: 0.8591\n",
      "Epoch 2/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3787 - accuracy: 0.8624 - val_loss: 0.3897 - val_accuracy: 0.8550\n",
      "Epoch 3/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3368 - accuracy: 0.8774 - val_loss: 0.3738 - val_accuracy: 0.8614\n",
      "Epoch 4/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3103 - accuracy: 0.8857 - val_loss: 0.3459 - val_accuracy: 0.8740\n",
      "Epoch 5/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2889 - accuracy: 0.8932 - val_loss: 0.3330 - val_accuracy: 0.8796\n",
      "Epoch 6/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2718 - accuracy: 0.8988 - val_loss: 0.3365 - val_accuracy: 0.8808\n",
      "Epoch 7/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2571 - accuracy: 0.9053 - val_loss: 0.3374 - val_accuracy: 0.8787\n",
      "Epoch 8/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2432 - accuracy: 0.9092 - val_loss: 0.3383 - val_accuracy: 0.8804\n",
      "Epoch 9/200\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2322 - accuracy: 0.9142 - val_loss: 0.3475 - val_accuracy: 0.8782\n",
      "Model arch 2,[batch_32,0.001,no_regularizer]=>Accuracy:0.880,F1:0.876\n",
      "Best model is: 1_batch_32_0.001_no_regularizer\n",
      "Confusion matrix\n",
      "[[902   0  10  10   1   0  70   0   7   0]\n",
      " [ 10 959   1  21   4   0   3   0   2   0]\n",
      " [ 28   0 852   4  76   0  39   0   1   0]\n",
      " [ 75   3  14 832  48   0  25   0   3   0]\n",
      " [  1   1 182  19 766   0  30   0   1   0]\n",
      " [  0   0   0   2   0 960   0  16   1  21]\n",
      " [190   0 133  17  79   0 573   0   8   0]\n",
      " [  0   0   0   0   0  29   0 948   1  22]\n",
      " [  7   0   3   4   6   3   4   3 970   0]\n",
      " [  0   0   0   1   0   5   1  64   0 929]]\n",
      "--------\n",
      "----------\n",
      "Final model results\n",
      "F1 Score(macro) 0.868032566481536\n",
      "Recall Score(macro) 0.8690999999999999\n",
      "Precision Score(macro) 0.8731474540096986\n",
      "Accuracy Score 0.8691\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.read_csv(\"logs/exp1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>regularizer</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1_score</th>\n",
       "      <th>converged_on</th>\n",
       "      <th>prefix</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>0.649417</td>\n",
       "      <td>0.626049</td>\n",
       "      <td>5</td>\n",
       "      <td>1_batch_8_0.01_regularizer</td>\n",
       "      <td>40.172384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>0.839667</td>\n",
       "      <td>0.838121</td>\n",
       "      <td>7</td>\n",
       "      <td>1_batch_8_0.01_no_regularizer</td>\n",
       "      <td>51.776132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>0.778083</td>\n",
       "      <td>0.776924</td>\n",
       "      <td>12</td>\n",
       "      <td>1_batch_8_0.001_regularizer</td>\n",
       "      <td>87.960952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>0.877250</td>\n",
       "      <td>0.875082</td>\n",
       "      <td>9</td>\n",
       "      <td>1_batch_8_0.001_no_regularizer</td>\n",
       "      <td>61.548300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>0.688917</td>\n",
       "      <td>0.666735</td>\n",
       "      <td>7</td>\n",
       "      <td>1_batch_32_0.01_regularizer</td>\n",
       "      <td>15.168335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>0.860250</td>\n",
       "      <td>0.856633</td>\n",
       "      <td>10</td>\n",
       "      <td>1_batch_32_0.01_no_regularizer</td>\n",
       "      <td>19.364543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>0.769083</td>\n",
       "      <td>0.759084</td>\n",
       "      <td>85</td>\n",
       "      <td>1_batch_32_0.001_regularizer</td>\n",
       "      <td>156.197915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>0.883917</td>\n",
       "      <td>0.882255</td>\n",
       "      <td>9</td>\n",
       "      <td>1_batch_32_0.001_no_regularizer</td>\n",
       "      <td>17.587077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>0.691750</td>\n",
       "      <td>0.672293</td>\n",
       "      <td>5</td>\n",
       "      <td>2_batch_8_0.01_regularizer</td>\n",
       "      <td>38.533837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>0.837000</td>\n",
       "      <td>0.834088</td>\n",
       "      <td>7</td>\n",
       "      <td>2_batch_8_0.01_no_regularizer</td>\n",
       "      <td>45.916781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>0.780917</td>\n",
       "      <td>0.776313</td>\n",
       "      <td>41</td>\n",
       "      <td>2_batch_8_0.001_regularizer</td>\n",
       "      <td>266.859499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>0.876500</td>\n",
       "      <td>0.873597</td>\n",
       "      <td>8</td>\n",
       "      <td>2_batch_8_0.001_no_regularizer</td>\n",
       "      <td>53.518954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>0.751083</td>\n",
       "      <td>0.744517</td>\n",
       "      <td>9</td>\n",
       "      <td>2_batch_32_0.01_regularizer</td>\n",
       "      <td>19.567394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>0.839833</td>\n",
       "      <td>0.837208</td>\n",
       "      <td>5</td>\n",
       "      <td>2_batch_32_0.01_no_regularizer</td>\n",
       "      <td>11.160685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>0.787833</td>\n",
       "      <td>0.778563</td>\n",
       "      <td>26</td>\n",
       "      <td>2_batch_32_0.001_regularizer</td>\n",
       "      <td>51.261501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "      <td>0.879583</td>\n",
       "      <td>0.876240</td>\n",
       "      <td>8</td>\n",
       "      <td>2_batch_32_0.001_no_regularizer</td>\n",
       "      <td>16.854792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  model  learning_rate  batch_size  regularizer  val_accuracy  \\\n",
       "0            0      1          0.010           8         True      0.649417   \n",
       "1            1      1          0.010           8        False      0.839667   \n",
       "2            2      1          0.001           8         True      0.778083   \n",
       "3            3      1          0.001           8        False      0.877250   \n",
       "4            4      1          0.010          32         True      0.688917   \n",
       "5            5      1          0.010          32        False      0.860250   \n",
       "6            6      1          0.001          32         True      0.769083   \n",
       "7            7      1          0.001          32        False      0.883917   \n",
       "8            8      2          0.010           8         True      0.691750   \n",
       "9            9      2          0.010           8        False      0.837000   \n",
       "10          10      2          0.001           8         True      0.780917   \n",
       "11          11      2          0.001           8        False      0.876500   \n",
       "12          12      2          0.010          32         True      0.751083   \n",
       "13          13      2          0.010          32        False      0.839833   \n",
       "14          14      2          0.001          32         True      0.787833   \n",
       "15          15      2          0.001          32        False      0.879583   \n",
       "\n",
       "    val_f1_score  converged_on                           prefix    duration  \n",
       "0       0.626049             5       1_batch_8_0.01_regularizer   40.172384  \n",
       "1       0.838121             7    1_batch_8_0.01_no_regularizer   51.776132  \n",
       "2       0.776924            12      1_batch_8_0.001_regularizer   87.960952  \n",
       "3       0.875082             9   1_batch_8_0.001_no_regularizer   61.548300  \n",
       "4       0.666735             7      1_batch_32_0.01_regularizer   15.168335  \n",
       "5       0.856633            10   1_batch_32_0.01_no_regularizer   19.364543  \n",
       "6       0.759084            85     1_batch_32_0.001_regularizer  156.197915  \n",
       "7       0.882255             9  1_batch_32_0.001_no_regularizer   17.587077  \n",
       "8       0.672293             5       2_batch_8_0.01_regularizer   38.533837  \n",
       "9       0.834088             7    2_batch_8_0.01_no_regularizer   45.916781  \n",
       "10      0.776313            41      2_batch_8_0.001_regularizer  266.859499  \n",
       "11      0.873597             8   2_batch_8_0.001_no_regularizer   53.518954  \n",
       "12      0.744517             9      2_batch_32_0.01_regularizer   19.567394  \n",
       "13      0.837208             5   2_batch_32_0.01_no_regularizer   11.160685  \n",
       "14      0.778563            26     2_batch_32_0.001_regularizer   51.261501  \n",
       "15      0.876240             8  2_batch_32_0.001_no_regularizer   16.854792  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model arch 1,batch_8,0.01,regularizer]\n",
      "Epoch 1/2\n",
      "6000/6000 [==============================] - 4s 706us/step - loss: 3.0395 - accuracy: 0.5842 - val_loss: 2.8110 - val_accuracy: 0.6099\n",
      "Epoch 2/2\n",
      "6000/6000 [==============================] - 4s 626us/step - loss: 2.8575 - accuracy: 0.6092 - val_loss: 2.7465 - val_accuracy: 0.6516\n",
      "Model arch 1,[batch_8,0.01,regularizer]=>Accuracy:0.652,F1:0.609\n",
      "Working on model arch 1,batch_8,0.01,no_regularizer]\n",
      "Epoch 1/2\n",
      "6000/6000 [==============================] - 4s 651us/step - loss: 0.6730 - accuracy: 0.7603 - val_loss: 0.7473 - val_accuracy: 0.7869\n",
      "Epoch 2/2\n",
      "6000/6000 [==============================] - 3s 575us/step - loss: 0.5682 - accuracy: 0.8095 - val_loss: 0.5929 - val_accuracy: 0.8056\n",
      "Model arch 1,[batch_8,0.01,no_regularizer]=>Accuracy:0.806,F1:0.800\n",
      "Working on model arch 1,batch_8,0.001,regularizer]\n",
      "Epoch 1/2\n",
      "6000/6000 [==============================] - 4s 706us/step - loss: 1.8564 - accuracy: 0.6818 - val_loss: 1.2694 - val_accuracy: 0.7347\n",
      "Epoch 2/2\n",
      "6000/6000 [==============================] - 4s 627us/step - loss: 1.2681 - accuracy: 0.7362 - val_loss: 1.2009 - val_accuracy: 0.7499\n",
      "Model arch 1,[batch_8,0.001,regularizer]=>Accuracy:0.750,F1:0.748\n",
      "Working on model arch 1,batch_8,0.001,no_regularizer]\n",
      "Epoch 1/2\n",
      "6000/6000 [==============================] - 4s 654us/step - loss: 0.5003 - accuracy: 0.8183 - val_loss: 0.4195 - val_accuracy: 0.8472\n",
      "Epoch 2/2\n",
      "6000/6000 [==============================] - 3s 574us/step - loss: 0.3805 - accuracy: 0.8603 - val_loss: 0.4170 - val_accuracy: 0.8558\n",
      "Model arch 1,[batch_8,0.001,no_regularizer]=>Accuracy:0.856,F1:0.850\n",
      "Working on model arch 1,batch_32,0.01,regularizer]\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 2s 973us/step - loss: 2.9717 - accuracy: 0.6328 - val_loss: 2.5274 - val_accuracy: 0.6723\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 1s 747us/step - loss: 2.5750 - accuracy: 0.6566 - val_loss: 2.6343 - val_accuracy: 0.6407\n",
      "Model arch 1,[batch_32,0.01,regularizer]=>Accuracy:0.641,F1:0.616\n",
      "Working on model arch 1,batch_32,0.01,no_regularizer]\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 2s 908us/step - loss: 0.5668 - accuracy: 0.7969 - val_loss: 0.4769 - val_accuracy: 0.8235\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 1s 688us/step - loss: 0.4608 - accuracy: 0.8352 - val_loss: 0.4769 - val_accuracy: 0.8288\n",
      "Model arch 1,[batch_32,0.01,no_regularizer]=>Accuracy:0.829,F1:0.821\n",
      "Working on model arch 1,batch_32,0.001,regularizer]\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 2s 965us/step - loss: 2.9610 - accuracy: 0.6766 - val_loss: 1.3847 - val_accuracy: 0.7002\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 1s 749us/step - loss: 1.2904 - accuracy: 0.7308 - val_loss: 1.2900 - val_accuracy: 0.7142\n",
      "Model arch 1,[batch_32,0.001,regularizer]=>Accuracy:0.714,F1:0.702\n",
      "Working on model arch 1,batch_32,0.001,no_regularizer]\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 2s 916us/step - loss: 0.5089 - accuracy: 0.8180 - val_loss: 0.3904 - val_accuracy: 0.8614\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 1s 691us/step - loss: 0.3783 - accuracy: 0.8618 - val_loss: 0.3740 - val_accuracy: 0.8669\n",
      "Model arch 1,[batch_32,0.001,no_regularizer]=>Accuracy:0.867,F1:0.864\n",
      "Working on model arch 2,batch_8,0.01,regularizer]\n",
      "Epoch 1/2\n",
      "6000/6000 [==============================] - 5s 734us/step - loss: 4.2369 - accuracy: 0.6408 - val_loss: 3.8732 - val_accuracy: 0.7093\n",
      "Epoch 2/2\n",
      "6000/6000 [==============================] - 4s 651us/step - loss: 4.0052 - accuracy: 0.6503 - val_loss: 3.8584 - val_accuracy: 0.6728\n",
      "Model arch 2,[batch_8,0.01,regularizer]=>Accuracy:0.673,F1:0.647\n",
      "Working on model arch 2,batch_8,0.01,no_regularizer]\n",
      "Epoch 1/2\n",
      "6000/6000 [==============================] - 4s 650us/step - loss: 0.6208 - accuracy: 0.7844 - val_loss: 0.5035 - val_accuracy: 0.8337\n",
      "Epoch 2/2\n",
      "6000/6000 [==============================] - 3s 566us/step - loss: 0.5342 - accuracy: 0.8181 - val_loss: 0.5037 - val_accuracy: 0.8292\n",
      "Model arch 2,[batch_8,0.01,no_regularizer]=>Accuracy:0.829,F1:0.821\n",
      "Working on model arch 2,batch_8,0.001,regularizer]\n",
      "Epoch 1/2\n",
      "6000/6000 [==============================] - 5s 741us/step - loss: 2.1111 - accuracy: 0.6936 - val_loss: 1.4399 - val_accuracy: 0.7400\n",
      "Epoch 2/2\n",
      "6000/6000 [==============================] - 4s 654us/step - loss: 1.4121 - accuracy: 0.7426 - val_loss: 1.3564 - val_accuracy: 0.7587\n",
      "Model arch 2,[batch_8,0.001,regularizer]=>Accuracy:0.759,F1:0.750\n",
      "Working on model arch 2,batch_8,0.001,no_regularizer]\n",
      "Epoch 1/2\n",
      "6000/6000 [==============================] - 4s 656us/step - loss: 0.4944 - accuracy: 0.8203 - val_loss: 0.4111 - val_accuracy: 0.8504\n",
      "Epoch 2/2\n",
      "6000/6000 [==============================] - 3s 572us/step - loss: 0.3733 - accuracy: 0.8622 - val_loss: 0.4018 - val_accuracy: 0.8523\n",
      "Model arch 2,[batch_8,0.001,no_regularizer]=>Accuracy:0.852,F1:0.848\n",
      "Working on model arch 2,batch_32,0.01,regularizer]\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 4.1697 - accuracy: 0.6795 - val_loss: 3.5407 - val_accuracy: 0.6942\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 1s 794us/step - loss: 3.6183 - accuracy: 0.7006 - val_loss: 3.5475 - val_accuracy: 0.7103\n",
      "Model arch 2,[batch_32,0.01,regularizer]=>Accuracy:0.710,F1:0.701\n",
      "Working on model arch 2,batch_32,0.01,no_regularizer]\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 2s 918us/step - loss: 0.5516 - accuracy: 0.8056 - val_loss: 0.4559 - val_accuracy: 0.8423\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 1s 706us/step - loss: 0.4477 - accuracy: 0.8377 - val_loss: 0.4226 - val_accuracy: 0.8487\n",
      "Model arch 2,[batch_32,0.01,no_regularizer]=>Accuracy:0.849,F1:0.848\n",
      "Working on model arch 2,batch_32,0.001,regularizer]\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 3.2274 - accuracy: 0.6842 - val_loss: 1.4683 - val_accuracy: 0.7131\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 1s 788us/step - loss: 1.3957 - accuracy: 0.7391 - val_loss: 1.3583 - val_accuracy: 0.7347\n",
      "Model arch 2,[batch_32,0.001,regularizer]=>Accuracy:0.735,F1:0.719\n",
      "Working on model arch 2,batch_32,0.001,no_regularizer]\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 2s 933us/step - loss: 0.5023 - accuracy: 0.8217 - val_loss: 0.3969 - val_accuracy: 0.8593\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 1s 709us/step - loss: 0.3776 - accuracy: 0.8636 - val_loss: 0.3872 - val_accuracy: 0.8573\n",
      "Model arch 2,[batch_32,0.001,no_regularizer]=>Accuracy:0.857,F1:0.851\n",
      "Best model is: 1_batch_32_0.001_no_regularizer\n",
      "Confusion matrix\n",
      "[[894   1  21  15   1   0  59   0   9   0]\n",
      " [  7 957   6  23   4   0   1   0   2   0]\n",
      " [ 24   0 886   5  52   0  31   0   2   0]\n",
      " [ 83  10   9 832  37   0  27   0   2   0]\n",
      " [  5   0 238  23 677   0  55   0   2   0]\n",
      " [  0   0   0   2   0 948   0  23   3  24]\n",
      " [232   1 189  19  66   0 475   0  18   0]\n",
      " [  0   0   0   0   0  33   0 933   1  33]\n",
      " [  7   0  13   9   5   3   5   3 955   0]\n",
      " [  0   0   0   1   0   6   0  44   1 948]]\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python CSCE479 (tensorflow-env)",
   "language": "python",
   "name": "tensorflow-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_datasets as tfds # to load training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "DATA_DIR=\"./tensorflow-datasets\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.random.set_seed(1024)\n",
    "\n",
    "\n",
    "\n",
    "#hyperparameter 1 batch_size = 8, batch_size = 32\n",
    "#hyperparameter 2 optimizer=adam or sgd with default learning rate\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(filename=\"experiment_log.csv\")\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_ds= tfds.load('fashion_mnist', split=\"train[:80%]\",data_dir=DATA_DIR, shuffle_files=False).map(lambda x: (tf.cast(x['image'],tf.float32)/255.0, x['label'])).batch(batch_size)\n",
    "val_ds= tfds.load('fashion_mnist', split=\"train[-20%:]\",data_dir=DATA_DIR, shuffle_files=False).map(lambda x: (tf.cast(x['image'],tf.float32)/255.0, x['label'])).batch(batch_size)\n",
    "\n",
    "# val_images,val_labels = tfds.load('fashion_mnist',split=\"train[-20%:]\",shuffle_files=False,as_supervised=True).batch(batch_size)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds,validation_data=val_ds,epochs=100,callbacks=[early_stopping_callback,csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils \n",
    "\n",
    "import numpy as np \n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    test_ds = utils.get_test_set()\n",
    "    predictions = model.predict(test_ds).argmax(axis=-1)\n",
    "    gt = np.concatenate([y for _, y in test_ds], axis=0)\n",
    "    acc_score = accuracy_score(gt,predictions)\n",
    "    f1 = f1_score(gt,predictions,average=\"macro\")\n",
    "    cf = confusion_matrix(gt,predictions)\n",
    "    return acc_score,f1,cf\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "pickle.dump(results,open(\"results\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1 = pickle.load(open(\"results\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model arch 1,[batch_8,adam,regularizer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-29 23:16:44.714341: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :\n",
      "2024-09-29 23:16:44.714375: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-09-29 23:16:44.714396: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c3618.swan.hcc.unl.edu): /proc/driver/nvidia/version does not exist\n",
      "2024-09-29 23:16:44.745915: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-29 23:16:45.524495: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Failed precondition: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 29.45 MiB (download: 29.45 MiB, generated: 36.42 MiB, total: 65.87 MiB) to ./tensorflow-datasets/fashion_mnist/3.0.1...\u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model arch 1,[batch_8,adam,regularizer]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 08:34:30.652389: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :\n",
      "2024-09-30 08:34:30.652425: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-09-30 08:34:30.652444: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c3618.swan.hcc.unl.edu): /proc/driver/nvidia/version does not exist\n",
      "2024-09-30 08:34:30.693964: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-30 08:34:31.795942: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6000/6000 [==============================] - 15s 2ms/step - loss: 1.7875 - accuracy: 0.6995 - val_loss: 1.2336 - val_accuracy: 0.7452\n",
      "Epoch 2/100\n",
      "6000/6000 [==============================] - 9s 2ms/step - loss: 1.2236 - accuracy: 0.7379 - val_loss: 1.1735 - val_accuracy: 0.7481\n",
      "Epoch 3/100\n",
      "6000/6000 [==============================] - 9s 2ms/step - loss: 1.1798 - accuracy: 0.7434 - val_loss: 1.1447 - val_accuracy: 0.7479\n",
      "Epoch 4/100\n",
      "6000/6000 [==============================] - 9s 2ms/step - loss: 1.1549 - accuracy: 0.7459 - val_loss: 1.1332 - val_accuracy: 0.7479\n",
      "Epoch 5/100\n",
      "5974/6000 [============================>.] - ETA: 0s - loss: 1.1392 - accuracy: 0.7480"
     ]
    }
   ],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python CSCE479 (tensorflow-env)",
   "language": "python",
   "name": "tensorflow-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
